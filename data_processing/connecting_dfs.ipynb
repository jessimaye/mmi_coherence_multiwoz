{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the current version of the dataframe as well as the data that should be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = []\n",
    "with open(\".csv\") as file1: #read in the current version of the dataframe\n",
    "    csvReader1 = csv.DictReader(file1)\n",
    "    for row in csvReader1: \n",
    "            liste.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste2 = []\n",
    "with open(\"API_2603/Teil6_annotation_llama3-8b.csv\", encoding=\"utf-8\") as file2:\n",
    "    csvReader2 = csv.DictReader(file2, delimiter=\";\")\n",
    "    for row in csvReader2: \n",
    "            #add this python dict to json array\n",
    "            liste2.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataframe of data that should be added to the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = pd.DataFrame(liste2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove entries with identical ids and texts\n",
    "\n",
    "note that for the speech acts based version this step should only be applied to the id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df2 = mini_df.drop_duplicates(subset='text', keep='first')\n",
    "mini_df3 = mini_df2.drop_duplicates(subset='id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dic  = mini_df3.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the mini-dataframe as atxt-file as well as the ids within the dataframe to check them for errors before the mini-dataframe is combined with the current version of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reduzierter_mini.txt', 'w+') as f:\n",
    "    for lem in mini_dic:\n",
    "        f.write(str(lem) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_ids = mini_df3.loc[:, 'id'].tolist()\n",
    "mini_sets = set(mini_ids)\n",
    "with open(\"mini_sets.txt\", \"w\") as file:\n",
    "    for elem in mini_sets:\n",
    "        file.write(elem + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after checking for errors, the txt-file is loaded in again and used as a basis for a dataframe which is then combined with the current dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reduzierter_mini.txt\", \"r\", encoding=\"utf-8\") as fi:\n",
    "    text = fi.readlines()\n",
    "fi.close()\n",
    "mini = []\n",
    "for elem in text:\n",
    "    mini.append(ast.literal_eval(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minidf = pd.DataFrame(mini)\n",
    "df = pd.DataFrame(liste)\n",
    "\n",
    "df = pd.concat([df, minidf], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates(subset='id', keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop_duplicates(subset='text', keep='first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic  = df3.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after transforming the dataframe into a dictionary-list, it is saved in the preferred format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.txt', 'w+', encoding=\"utf-8\") as f:\n",
    "    for lem in dic:\n",
    "        f.write(str(lem) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.json',\"w+\") as fi:\n",
    "    for elem in dic:\n",
    "        json.dump(elem, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
